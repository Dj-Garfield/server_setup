services:
  cuda:
    build:
      context: .
      dockerfile: Dockerfile_cuda
    container_name: cuda8.0
    devices:
    - /dev/nvidia0
    - /dev/nvidiactl
    - /dev/nvidia-uvm
    - /dev/nvidia-uvm-tools
    environment:
    - DISPLAY=$DISPLAY
    volumes:
    - ./project:/root/project
    - /tmp/.X11-unix:/tmp/.X11-unix
    - nvidia_driver_384.69:/usr/local/nvidia:ro
  tensorflow:
    build:
      context: .
      dockerfile: Dockerfile_tensorflow
    container_name: tensorflow
    devices:
    - /dev/nvidia0
    - /dev/nvidiactl
    - /dev/nvidia-uvm
    - /dev/nvidia-uvm-tools
    environment:
    - DISPLAY=$DISPLAY
    ports:
    - 8888:8888
    restart: always
    volumes:
    - ./project:/root/project
    - /tmp/.X11-unix:/tmp/.X11-unix
    - nvidia_driver_384.69:/usr/local/nvidia:ro
version: '2'
volumes:
  nvidia_driver_384.69:
    external: true
